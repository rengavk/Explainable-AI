My thesis proposes a framework for generating **minimal counterfactual explanations in Group Recommender Systems (GRS)** using the MovieLens 1M dataset. The approach combines collaborative filtering, user-group similarity, and a novel item-scoring function with clustering to identify the smallest set of items influencing a recommendation outcome.

By removing “influential clusters,” we explain why certain items appear (or don’t) in group recommendations, offering greater transparency. Results show key differences between homogeneous and heterogeneous groups of 5 users, with outcomes shaped by group diversity, clustering choices, and the weighting of three factors: **intensity, popularity, and relevance**.
This work highlights how counterfactual reasoning can improve accountability and transparency in GRS, providing both **quantitative metrics and qualitative insights** into how small changes in preferences can shift recommendation results.

