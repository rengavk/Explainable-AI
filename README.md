My thesis presents a framework for generating** minimal counterfactual explanations in the context of Group Recommender Systems (GRS)**. Using the 1M MovieLens dataset, my approach integrates collaborative filtering techniques, user similarity-based grouping, and a novel item-scoring function. We then cluster items to identify and remove “influential clusters” to pinpoint the smallest subset of items responsible for a specific recommendation outcome. By explaining group recommendations through minimal counterfactuals, our work provides a more transparent view of how a recommended item can appear or be excluded based on other items in the group’s preference set. 

These results also highlight notable differences in explanatory patterns between homogeneous (“similar”) and heterogeneous (“dissimilar”) groups of user size 5. We show that these subsets vary in size and composition depending on group similarity or diversity, the weighting of our item-scoring components with changes in weights of three components), 
and the chosen clustering strategy. we explore how varying the emphasis on three key factors - (i) intensity, (ii) popularity, and (iii) relevance—affects recommendations and the identification of influential clusters. These findings underscore the critical role of weighting strategies in balancing global acceptance (popularity), group cohesion (intensity), and personalized alignment (relevance), providing both quantitative metrics and qualitative insights to enhance the transparency of GRS. This underscores the power of counterfactual reasoning in group settings, providing stakeholders with deeper insights into why certain items are recommended and how minor adjustments can lead to alternative outcomes. This research contributes to improving accountability and transparency of group recommender systems by demonstrating a scalable procedure for generating minimal, actionable explanations.
